\chapter[quantitative-rules]{初等采样理论}

至此，我们所拥有并且有效的数学基础由基本的乘法和加法规则构成：

\placeformula[3-1]
\startformula
P(AB|C) = P(A|BC)P(B|C) = P(B|AC)P(A|C)
\stopformula

\placeformula[3-2]
\startformula
P(A|B) + P(\itbar{A}|B) = 1
\stopformula

从它们可以导出扩展的加法规则：

\placeformula[3-3]
\startformula
P(A + B|C) = P(A|C) + P(B|C) - P(AB|C)
\stopformula

使用一致性的祈求 (\Roman{3}c)，亦即无差异性原理：如果一组假设 $(H_1,H_2,\cdots,H_N)$ 在背景信息 $B$ 上相互独立且详尽，并且 $B$ 不会偏好这些假设中的任何一个，那么

\placeformula[3-4]
\startformula
P(H_i|B) = \frac{1}{N}\quad\quad 1\le i \le N
\stopformula

从 (\in[3-3]) 和 (\in[3-4]) 又可以推导出 Bernoulli 瓮规则：如果 $B$ 指定了 $A$ 在 $M$ 个假设所构成的子集上为真，而在剩下的 $(N - M)$ 假设所构成的子集为假，那么

\placeformula[3-5]
\startformula
P(A|B) = \frac{M}{N}
\stopformula

意识到概率论在内容上有多少能够仅仅从此式推导出来，这一点非常重要。

实际上，当前所教授的概率论的全部内容，加上许多经常重要结果——它们经常被视为超出了概率论范围，可以从上述基础推导出来。接下来的几章内容会给出一些细节，而后在第 11 章，继续发展我们的机器人的大脑，让它能够充分理解高级应用所需要的另外一些原理。

在本章中，我们的概率论，它的第一个应用与我们之后所期望达到的严肃科学推断相比，相当简单和幼稚。无论如何，我们从细节上来考虑这些，原因并不仅仅是面向教学。对于这些最为简单的应用，对其逻辑的误解，是几十年来阻碍科学推断发展进程——也包含科学本身——的主要原因之一。因而我们强烈建议读者，即使你早已熟悉初等采样理论，在处理更为复杂的问题之前，也应当认真消化本章内容。

\section{无放回采样}

为了让 Bernoulli 瓮更为明确，我们定义了以下命题：

\definedescription[mydefinition][location=left, before=, after=, headstyle=\tf, width=broad, distance=0.25em]
\def\myproposition#1{\hbox to 1.5em{#1}$\equiv$}
\mydefinition{\myproposition{$B$}} 有个瓮，里面有 $N$ 个球。它们的编号是 $(1,2,\cdots,N)$，其中有 $M$ 个球是红色的，其余的是白色的，$0\le M \le N$。除此之外，这些球的各方面都相同。闭着眼从瓮中取一个球，观察并记录它的颜色，再把它放回去。重复这一过程 $n$ 次，$0\le n \le N$。\par
\mydefinition{\myproposition{$R_i$}} 第 $i$ 次取的球为红色。\par
\mydefinition{\myproposition{$W_i$}} 第 $i$ 次取的球为白色。\par

根据 $B$，能够取的球仅有红色和白色，有

\placeformula[3-6]
\startformula
P(R_i|B) + P(W_i|B) = 1\quad\quad 1\le i \le N
\stopformula

它等同于说，在知识 $B$ 所创立的\quotation{逻辑环境}里，命题 $R_i$ 与 $W_i$ 的关系是互反的，即

\placeformula[3-7]
\startformula
\itbar{R_i} = W_i\quad\quad \itbar{W_i} = R_i
\stopformula

并且，对于第一次取球，(\in[3-5]) 变为

\placeformula[3-8]
\startformula
P(R_i|B) = \frac{M}{N}
\stopformula

\placeformula[3-9]
\startformula
P(W_i|B) = 1 - \frac{M}{N}
\stopformula

现在来看这意味着什么。概率赋值 (\in[3-8]) 和 (\in[3-9]) 所断言的并非瓮的物理属性或其内容；它们描述的是机器人在取球之前所具备的{\bf 知识状态}。实际上，倘若机器人的知识状态与上面定义的 $B$ 有所不同（例如，它知道红球和白球在瓮内的位置，或者它不知道 $N$ 和 $M$ 多大），那么它为 $R_i$ 和 $W_i$ 所赋的概率必然与 (\in[3-8]) 和 (\in[3-9]) 不同，而瓮的现实属性却不会变。

因此，称用瓮来做实验以\quotation{验证}(\in[3-8])，这种说法，如同在狗身上做实验来验证一个孩子对他的狗的喜爱，毫无逻辑可言。眼下，我们关心的是来自不完备信息的一致性推理所涉及的逻辑，而不是瓮中取出什么东西这一物理现象的断言（任何情况下，着都是不可能做到的，因为信息 $B$ 不完备）。

最终，我们的机器人将会能够作出一些非常肯定的现实预测。这些预测能够接近，但是（除非在一些退化的情况下）并不能真正达到逻辑演绎的确定性；但是，在我们能够说出什么量能够被准确预测并且为此需要何种信息之前，理论还需要进一步发展。换言之，由机器人在不同知识状态下所赋的概率与实验中可观察到的事实，这二者之间的关系可能并非随意建立的；我们有充分的理由仅仅使用可由概率论规则推导出来的那些关系，这是是我们现在正要去做的的事。

当我们向机器人索取与第二次抽取相关的概率时，机器人的知识状态便会出现变化。例如，开始的两次取球，取到的皆为红球的概率是多大？根据乘法规则，这个概率为

\placeformula[3-10]
\startformula
P(R_1R_2|B) = P(R_1|B)P(R_2|R_1B)
\stopformula

在最后一个因子中，机器人必须考虑第一所取的红球已经从瓮中移除，因此瓮中所剩下的 $(N - 1)$ 个球中有 $(M - 1)$ 个是红球。因而

\placeformula[3-11]
\startformula
P(R_1R_2|B) = \frac{M}{N}\frac{M - 1}{N - 1}
\stopformula

沿着这一思路，前 $r$ 次连续取球，所取之球皆为红球的概率为

\placeformula[3-12]
\startformula
\startmathalignment[style=\displaystyle]
\NC P(R_1R_2\cdots R_r|B) \NC = \frac{M(M - 1)\cdots (M - r + 1)}{N(N - 1)\cdots (N - r + 1)}\NR
\NC \NC = \frac{M!(N - r)!}{(M - r)!N!}\quad\quad r\le M\NR
\stopmathalignment
\stopformula

倘若我们用伽马函数关系 $n! = \Gamma(n + 1)$ 来定义阶乘，则限制条件 $r\le M$ 并非必须，因为当 $r > M$ 时，负整数的阶乘结果为无穷大，于是 (\in[3-12]) 的结果自动为 0。

前 $w$ 次取球，取到的球皆为白球的概率与 (\in[3-12]) 相似，只是要将 $M$ 换成 $(N - M)$：

\placeformula[3-13]
\startformula
P(W_1W_2\cdots W_w|B) = \frac{(N - M)!(N - w)!}{(N - M - w)!N!}
\stopformula

假设前 $r$ 次取球，取到的皆为红球，那么在 $(r + 1, r + 2, \cdots,r + w)$ 次取球，取到的皆为白球的概率，需要在 (\in[3-13]) 的基础上考虑 $N$ 和 $M$ 已分别缩减为 $(N - r)$ 和 $(M - r)$：

\placeformula[3-14]
\startformula
P(W_1W_2\cdots W_w|R_1\cdots R_rB) = \frac{(N - M)!(N - r - w)!}{(N - M - w)!(N - r)!}
\stopformula

因此，通过乘法规则，在 $n$ 次取球的过程中，取出 $r$ 个红球之后，又取出 $w = n - r$ 个白球的概率，由 (\in[3-12]) 和 (\in[3-14]) 可得

\placeformula[3-15]
\startformula
P(R_1\cdots R_rW_{r + 1}\cdots W_n|R_1\cdots R_rB) = \frac{M!(N - M)!(N - n)!}{(M - r)!(N - M - w)!N!}
\stopformula

$(N - r)!$ 项被约掉了。

尽管这个结果基于红球和白球特定的取出顺序推导出来，但是以任何特定顺序在 $n$ 次取球中取出 $r$ 个红球，概率都是相同的。为了看清这一点，需要采用下面的方式

\placeformula[3-16]
\startformula
\frac{M!}{(M - r)!} = M(M - 1)\cdots (M - r + 1)
\stopformula

对 (\in[3-15]) 的其他比率作更完全地展开。于是 (\in[3-15]) 的右部变为

\placeformula[3-17]
\startformula
\frac{M(M - 1)\cdots (M - r + 1)(N - M)(N - M - 1)\cdots (N - M - w + 1)}{N(N - 1)\cdots (N - n + 1)}
\stopformula

现在假设 $r$ 个红球和 $(n - r) = w$ 个白球以任意次序被取出。这种情况的概率是 $n$ 个因子的积；每次取到红球，就会存在一个因子 $\displaystyle\frac{(\text{瓮内红球的数量})}{(\text{瓮内球的总数})}$，并且，同样可以为取到白球写出相似的因子。每次取球，瓮内的球的数量便会少一个；因而第 $k$ 次取球，$(N - k + 1)$ 就会在分母中出现，无论在取这个球之前所取的那些球是什么颜色。

就在第 $k$ 个红球被取出之前，无论这个球是在第 $k$ 次还是第 $k$ 次之后的任意一次取球时被取出，瓮内剩下 $(M - k + 1)$ 个红球；因而，取第 $k$ 个球，就相当于在分子上放了一个因子 $(M - k + 1)$。就在第 $k$ 个白球被取出之前，瓮内剩下 $(N - M - k + 1)$ 个红球；因而，取第 $k$ 个球，无论这个球是在第 $k$ 次还是第 $k$ 次之后的任意一次取球时被取出，就相当于在分子上放了一个因子 $(N - M - k + 1)$。因而，此时 $n$ 个球皆已取出，其中 $r$ 个是红球，我们在分子和分母上累积的因子与 (\in[3-17]) 相同；不同的取球次序仅仅是排列分子中因子的次序罢了。因此，在 $n$ 次取球的过程中，以任意次序刚好取出 $r$ 个红球，这种情况的概率皆由 (\in[3-15]) 而定。

务必注意，在这个结果中，乘法规则是以一种特殊的方式展开的，这种方式向我们揭示了如何将计算组织成因子的乘积，每一个因子都是一次特定的取球结果的概率，{\bf 这个结果是由之前的所有取球的结果给定的}。